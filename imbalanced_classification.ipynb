{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Working through the 'Mini-Course' from MachineLearningMastery: https://machinelearningmastery.com/imbalanced-classification-with-python-7-day-mini-course/\n",
    "Q: What is an imbalanced classification problem and why do we care? \n",
    "A: A classification problem where the classes are not split evenly is an imbalanced classification problem. The issue with\n",
    "   problems like this is that a generic model will suffer from poor performance due to the data imbalance. These problems \n",
    "   will be pretty common, like a fraudulent credit card model, where 1/100,000 transactions is fraudulent. \n",
    "This notebook will cover all lessons:\n",
    "Lesson 01: Challenge of Imbalanced Classification\n",
    "Lesson 02: Intuition for Imbalanced Data\n",
    "Lesson 03: Evaluate Imbalanced Classification Models\n",
    "Lesson 04: Undersampling the Majority Class\n",
    "Lesson 05: Oversampling the Minority Class\n",
    "Lesson 06: Combine Data Undersampling and Oversampling\n",
    "Lesson 07: Cost-Sensitive Algorithms\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lesson 01: Challenge of Imbalanced Classification\n",
    "\"\"\"Examples for Imbalanced Classification:\n",
    "1. Fraudulent Credit Card Transaction Detection\n",
    "2. Genetic Screening\n",
    "3. Mechanical Breakdown Prediction \n",
    "4. Anything related to Churn possibly\n",
    "5. Webpage Ad Analytics\n",
    "6. Diabetes screening\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 900, 1: 100})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lesson 02: Intuition for Imbalanced Data\n",
    "\"\"\"Below we will create some generic classification dataset with sklearns make_classification.\n",
    "Class 1: 90% Class 2: 10%, so highly imbalanced. We will then plot with pyplot to visualize.\"\"\"\n",
    "# plot imbalanced classification problem\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.90, 0.10], flip_y=0)\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992\n",
      "Precision: 0.991\n",
      "Recall: 0.926\n",
      "F-measure: 0.958\n",
      "Fbeta-measure(beta=1): 0.958\n",
      "Fbeta-measure(beta=0.5): 0.978\n",
      "Fbeta-measure(beta=2): 0.938\n"
     ]
    }
   ],
   "source": [
    "#Lesson 03: Evaluate Imbalanced Classification Models\n",
    "\"\"\"We will answer the question of how to evaluate these models. The typical evaluation metric is accuracy, which is a foolish\n",
    "metric for these kinds of problems as labeling everything as class 1 and yield high accuracy, proportional the the skew.\n",
    "Now what about Precision/Recall? Maximizing precision will minimize the false positives, and maximizing recall will minimize \n",
    "false negatives. Both of these are useful, so we will use both. Introducing the F-score. Where:\n",
    "F-score = (2 * Precision * Recall) / (Precision + Recall)\n",
    "The F-measure is calculated as the harmonic mean of precision and recall, giving each the same weighting, so it's a good place \n",
    "to start, let's do an example.\"\"\"\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# generate dataset like above\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.90], flip_y=0)\n",
    "\n",
    "# split into train/test sets with same class ratio\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "\n",
    "# define some arbitrary model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# fit model\n",
    "model.fit(trainX, trainy)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "# evaluate predictions\n",
    "print('Accuracy: %.3f' % accuracy_score(testy, yhat))\n",
    "print('Precision: %.3f' % precision_score(testy, yhat))\n",
    "print('Recall: %.3f' % recall_score(testy, yhat))\n",
    "print('F-measure: %.3f' % f1_score(testy, yhat))\n",
    "\n",
    "\"\"\"As we can see that accuracy was probably great, but since the weighting is 90% class 1, how much of a model is this? Could be as \n",
    "simple as input value = class 1, and it would still be right 90% of the time. Let's look at another scoring metric:\n",
    "Fbeta-measure: https://machinelearningmastery.com/fbeta-measure-for-machine-learning/\n",
    "The Fbeta-measure skews the weighting of the average between precision and recall. The \"beta\" is a constant for skewing the weight \n",
    "of the score between favoring precision (beta<1), favoring recall (beta>1). A beta = 1 is just the regular f-score.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "print('Fbeta-measure(beta=1): %.3f' % fbeta_score(testy, yhat, beta=1))\n",
    "print('Fbeta-measure(beta=0.5): %.3f' % fbeta_score(testy, yhat, beta=0.5))\n",
    "print('Fbeta-measure(beta=2): %.3f' % fbeta_score(testy, yhat, beta=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 200, 1: 100})\n",
      "Accuracy: 0.993\n",
      "Precision: 1.000\n",
      "Recall: 0.980\n",
      "F-measure: 0.990\n"
     ]
    }
   ],
   "source": [
    "#Lesson 04: Undersampling the Majority Class\n",
    "\"\"\"One option to solve this issue is to resample the data to get a better distribution. There is a library \"imbalanced-learn\".\n",
    "\"\"\"\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99, 0.01], flip_y=0)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_under))\n",
    "\n",
    "# re-do the model from above\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X_under, y_under, test_size=0.5, stratify=y_under)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(trainX, trainy)\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "print('Accuracy: %.3f' % accuracy_score(testy, yhat))\n",
    "print('Precision: %.3f' % precision_score(testy, yhat))\n",
    "print('Recall: %.3f' % recall_score(testy, yhat))\n",
    "print('F-measure: %.3f' % f1_score(testy, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 9900, 1: 4950})\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F-measure: 1.000\n"
     ]
    }
   ],
   "source": [
    "#Lesson 05: Oversampling the Minority Class\n",
    "\"\"\"And as no surprise another option is to do the opposite, and oversample the minority class. We will look at \n",
    "Synthetic Minority Oversampling Technique (SMOTE). This does a little more than duplicating the minority class, it does so with \n",
    "tiny variations in values, using k-nearest clustering.\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99, 0.01], flip_y=0)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "\n",
    "# define oversample strategy\n",
    "oversample = SMOTE(sampling_strategy=0.5)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))\n",
    "\n",
    "# re-do the model from above\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X_over, y_over, test_size=0.5, stratify=y_over)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(trainX, trainy)\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "print('Accuracy: %.3f' % accuracy_score(testy, yhat))\n",
    "print('Precision: %.3f' % precision_score(testy, yhat))\n",
    "print('Recall: %.3f' % recall_score(testy, yhat))\n",
    "print('F-measure: %.3f' % f1_score(testy, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 9900, 1: 4950})\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F-measure: 1.000\n"
     ]
    }
   ],
   "source": [
    "#Lesson 06: Combine Data Undersampling and Oversampling\n",
    "\"\"\"Naturally the next step is to find use for both of these processes. There are a few techniques:\n",
    "* Random Undersampling with SMOTE oversampling.\n",
    "* Tomek Links Undersampling with SMOTE oversampling.\n",
    "* Edited Nearest Neighbors Undersampling with SMOTE oversampling.\n",
    "The below example will use the SMOTEENN class to perform over-sampling using SMOTE and cleaning using ENN.\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99, 0.01], flip_y=0)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define sampling strategy\n",
    "sample = SMOTEENN(sampling_strategy=0.5)\n",
    "# fit and apply the transform\n",
    "X_smoteenn, y_smoteenn = sample.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y_smoteenn))\n",
    "\n",
    "# re-do the model from above\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X_smoteenn, y_smoteenn, test_size=0.5, stratify=y_smoteenn)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(trainX, trainy)\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "print('Accuracy: %.3f' % accuracy_score(testy, yhat))\n",
    "print('Precision: %.3f' % precision_score(testy, yhat))\n",
    "print('Recall: %.3f' % recall_score(testy, yhat))\n",
    "print('F-measure: %.3f' % f1_score(testy, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.239\n"
     ]
    }
   ],
   "source": [
    "#Lesson 07: Cost-Sensitive Algorithms\n",
    "\"\"\"Cost-sensitive learning is a subfield of machine learning that takes the costs of prediction errors \n",
    "(and potentially other costs) into account when training a machine learning model. A highly relevant example\n",
    "is Covid-19 testing, where the cost of a false negative is far higher than a false positive. Cost-sensitive \n",
    "techniques may be divided into three groups: \n",
    "* Data resampling \n",
    "* Algorithm modifications\n",
    "* Ensemble methods.\n",
    "I didn't think the \"lesson\" gave enough detail, so may do an additional book concerning Cost-sensitive Algos.\n",
    "But below we will look at the class_weight attribute in the sk-learn algorthm LogisticRegression. Weights \n",
    "associated with classes are in the form {class_label: weight}, or 'balanced'.\n",
    "\"\"\"\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99], flip_y=0)\n",
    "# split into train/test sets with same class ratio\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "# define model\n",
    "model = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "# fit model\n",
    "model.fit(trainX, trainy)\n",
    "# predict on test set\n",
    "yhat = model.predict(testX)\n",
    "# evaluate predictions\n",
    "print('F-Measure: %.3f' % f1_score(testy, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
